{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ IESA DeepTech Hackathon 2026 - Quick Start\n",
    "\n",
    "**Edge AI Defect Detection System**  \n",
    "One-click training pipeline for Google Colab\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "1. Upload `Dataset.zip` to your Google Drive\n",
    "2. Ensure dataset structure: `Dataset/{train,val,test}/{class_folders}`\n",
    "3. Run cells sequentially\n",
    "\n",
    "**Estimated Runtime**: 2-3 hours (with GPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "# Enable GPU acceleration\n",
    "import tensorflow as tf\n",
    "print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repository (replace with your GitHub URL)\n",
    "!git clone https://github.com/yourusername/iesa-defect-detection.git\n",
    "%cd iesa-defect-detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Mount Google Drive & Extract Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Verify dataset location\n",
    "import os\n",
    "dataset_zip = \"/content/drive/MyDrive/Dataset.zip\"\n",
    "\n",
    "if os.path.exists(dataset_zip):\n",
    "    print(f\"‚úÖ Dataset found: {dataset_zip}\")\n",
    "else:\n",
    "    print(\"‚ùå Dataset.zip not found! Please upload to Google Drive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract dataset\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall('/content/')\n",
    "\n",
    "print(\"‚úÖ Dataset extracted to /content/Dataset\")\n",
    "\n",
    "# Verify structure\n",
    "!ls -lh /content/Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Run Full Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run complete pipeline (wafer + die training)\n",
    "!python iesa_defect_detection_pipeline.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metrics\n",
    "import json\n",
    "\n",
    "with open('outputs/results/wafer_metrics.json', 'r') as f:\n",
    "    wafer_metrics = json.load(f)\n",
    "\n",
    "print(\"Wafer Model Performance:\")\n",
    "print(json.dumps(wafer_metrics['metrics'], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display confusion matrix\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename='outputs/results/wafer_confusion_matrix.png'))\n",
    "display(Image(filename='outputs/results/wafer_confidence_dist.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Test Inference Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import inference module\n",
    "from iesa_defect_detection_pipeline import InferencePipeline\n",
    "\n",
    "# Load models\n",
    "pipeline = InferencePipeline(\n",
    "    wafer_model_path=\"outputs/models/wafer_best.h5\",\n",
    "    die_model_path=\"outputs/models/die_best.h5\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Inference pipeline ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on sample image\n",
    "import glob\n",
    "\n",
    "# Get first test image\n",
    "test_images = glob.glob('/content/Dataset/test/**/*.jpg', recursive=True)\n",
    "sample_image = test_images[0]\n",
    "\n",
    "# Run inference\n",
    "result = pipeline.predict(sample_image, use_tiling=True, early_exit=True)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INFERENCE RESULT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Image: {sample_image}\")\n",
    "print(f\"Stage: {result['stage']}\")\n",
    "print(f\"Predicted Class: {result['predicted_class']}\")\n",
    "print(f\"Confidence: {result['confidence']:.2%}\")\n",
    "print(f\"Early Exit: {result['early_exit']}\")\n",
    "print(f\"Tiling Used: {result['tiling_used']}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show image\n",
    "from PIL import Image\n",
    "display(Image.open(sample_image).resize((400, 400)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Download Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip all outputs\n",
    "!zip -r outputs.zip outputs/\n",
    "\n",
    "# Download to local machine\n",
    "from google.colab import files\n",
    "files.download('outputs.zip')\n",
    "\n",
    "print(\"‚úÖ Download started! Check your browser's download folder.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Export ONNX Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX models should be already exported by the pipeline\n",
    "# Verify they exist\n",
    "import os\n",
    "\n",
    "onnx_files = [\n",
    "    'outputs/models/wafer_model.onnx',\n",
    "    'outputs/models/die_model.onnx'\n",
    "]\n",
    "\n",
    "for file in onnx_files:\n",
    "    if os.path.exists(file):\n",
    "        size_mb = os.path.getsize(file) / (1024 * 1024)\n",
    "        print(f\"‚úÖ {file} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file} not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "1. **Review Metrics**: Check `outputs/results/` for detailed performance reports\n",
    "2. **Test Edge Deployment**: Use `wafer_model.onnx` and `die_model.onnx` with NXP eIQ\n",
    "3. **Iterate**: Adjust hyperparameters in `Config` class for better performance\n",
    "4. **Create Submission**: Package code, models, and report for hackathon\n",
    "\n",
    "---\n",
    "\n",
    "**Questions?** Check README.md for detailed documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
